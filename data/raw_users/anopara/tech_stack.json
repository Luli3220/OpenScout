[
  {
    "name": "anopara/genetic-drawing",
    "stars": 2222,
    "description": "A genetic algorithm toy project for drawing",
    "languages_breakdown": {
      "Python": 14422,
      "Jupyter Notebook": 1906
    },
    "files": {
      "README.md": "# Genetic Drawing\nThis is a toy project I did around 2017 for imitating a drawing process given a target image (inspired by many examples of genetic drawing on the internet, and this was my take on it, mostly as an exercise). \n\nDue to a popular request, it is now opensource ðŸ™‚\n\nExamples of generated images:\n\n![](imgs/img1.gif) <img src=\"imgs/img2.gif\" width=\"380\">\n\nIt also supports user-created sampling masks, in case you'd like to specify regions where more brushstrokes are needed (for ex, to allocate more finer details)\n\n\n<img src=\"imgs/img3.gif\">\n\n\n## Python\nyou would need the following python 3 libraries:\n\n* opencv 3.4.1\n* numpy 1.16.2\n* matplotlib 3.0.3\n* and Jupyter Notebook\n\nTo start, open the GeneticDrawing.ipynb and run the example code\n"
    }
  },
  {
    "name": "anopara/country-slice",
    "stars": 434,
    "description": "æ— ",
    "languages_breakdown": {
      "Rust": 174679,
      "GLSL": 23134
    },
    "files": {
      "Cargo.toml": "[package]\nname = \"country-slice\"\nversion = \"0.2.0\"\nedition = \"2018\"\n\nauthors = [\"Anastasia Opara <anastasiaopara@gmail.com>\"] \n\n# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html\n\n[dependencies]\ngl = \"0.14.0\"\nglutin = \"0.27.0\"\nglam = \"0.20.0\"\ngltf = \"0.16.0\"\ndolly = \"0.1.4\"\nhotwatch = \"0.4.6\"\nbevy_app = \"0.5\"\nbevy_core = \"0.5\"\nbevy_ecs = \"0.5\"\nbevy_input = \"0.5\"\nfastrand = \"1.5.0\"\nlog = \"0.4.14\"\nsimple_logger = \"1.13.0\"\nserde_json = \"1.0\"\npuffin = \"0.12.1\"\npuffin_http = \"0.9.0\"\nbracket-noise = \"0.8.2\" #terrain noise\nlazy_static = \"1.4.0\"",
      "README.md": "# country-slice\n\nMy small hobby toy project, written in [Rust language](https://www.rust-lang.org/) with [Bevy](https://github.com/bevyengine/bevy)'s ECS and OpenGL ([gl-rs](https://github.com/brendanzab/gl-rs/tree/master/gl) and [glutin](https://github.com/rust-windowing/glutin)).\n\n### Build and Run\n\n1. download the repo\n2. cd to the `country-slice` directory\n3. execute `cargo run --release`, this will build and run the app\n\n### References\n\n* Marc Chevry's [Making Of Minimoys Procedural Wall](https://www.artstation.com/blogs/marcchevry/YMYR/making-of-minimoys-procedural-wall)\n\n\n"
    }
  },
  {
    "name": "anopara/patch-based-texture-synthesis",
    "stars": 217,
    "description": "Based on \"Image Quilting for Texture Synthesis and Transfer\" and \"Real-Time Texture Synthesis by Patch-Based Sampling\" papers",
    "languages_breakdown": {
      "Jupyter Notebook": 140339,
      "Python": 19146
    },
    "files": {
      "README.md": "# patch-based-texture-synthesis\nBased on \"Image Quilting for Texture Synthesis and Transfer\" and \"Real-Time Texture Synthesis by Patch-Based Sampling\" papers\n\n![](exampleGif.gif)\n\n### Python\n\nHere are the libraries and their versions you will need:\n* Python 3.7\n* Jupyter Notebook (5.6.0)\n* Numpy (is 1.15.1)\n* Matplotlib (2.2.3)\n* Scipy (1.1.0)\n* Skimage (0.14.0)\n* scikit-learn (0.19.2)\n* imageio (2.4.1)\n* PIL (5.2.0)\n\nTo start, open the Jupyter Notebook file \"Patch-based Texture Synthesis\", and follow the instructions :) \n\nBelow you can see the effect of different patch sizes:\n![](differentPatchSizes_example.gif)\n"
    }
  }
]