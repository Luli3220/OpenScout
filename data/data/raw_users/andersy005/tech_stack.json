[
  {
    "name": "andersy005/tvm-in-action",
    "stars": 64,
    "description": "TVM stack: exploring the incredible explosion of deep-learning frameworks and how to bring them together ",
    "languages_breakdown": {
      "Jupyter Notebook": 59630,
      "Makefile": 2083
    },
    "files": {
      "README.md": "![](http://tvmlang.org/images/main/stack_tvmlang.png) (Image Source: http://tvmlang.org/)\n\n# TVM in Action\n\n[TVM: End-to-End Optimization Stack for Deep Learning](https://github.com/dmlc/tvm)\n\nThis repo hosts my notes, tutorial materials (source code) for TVM stack as I explore the incredible explosition of deep-learning frameworks and how to bring them together. \n\n# [Summary of TVM: End-to-End Optimization Stack for Deep Learning](https://arxiv.org/abs/1802.04799)\n\n## Abstract\n\n- Scalable frameworks, such as TensorFlow, MXNet, Caffe, and PyTorch are optimized for a narrow range of serve-class GPUs.\n- Deploying workloads to other platforms such as mobile phones, IoT, and specialized accelarators(FPGAs, ASICs) requires laborious manual effort.\n- TVM is an end-to-end optimization stack that exposes:\n  - graph-level\n  - operator-level optimizations\n  ---> to provide performance portability to deep learning workloads across diverse hardware back-ends.\n\n## Introduction\n\n- The number and diversity of specialized deep learning (DL) accelerators pose an adoption challenge\n  - They introduce new hardware abstractions that modern compilers and frameworks are ill-equipped to deal with.\n\n- Providing support in various DL frameworks for diverse hardware back-ends in the present ad-hoc fashion is **unsustainable**.\n\n- Hardware targets significantly diverge in terms of memory organization, compute, etc..\n\n![](https://i.imgur.com/XRSZMt0.png)\n\n- *The Goal*: **easily deploy DL workloads to all kinds of hardware targets, including embedded devives, GPUs, FPGAs, ASCIs (e.g, the TPU).**\n\n- Current DL frameworks rely on a **computational graph intermediate representation** to implement optimizations such as:\n  - auto differentiation\n  - dynamic memory management\n\n- **Graph-level optimizations** are often too high-level to handle hardware back-end-specific **operator transformations**.\n- **Current operator-level libraries** that DL frameworks rely on are:\n  - too rigid\n  - specialized\n\n  ---> to be easily ported **across hardware devices**\n\n- To address these weaknesses, we need a **compiler framework** that can expose optimization opportunities across both\n  - graph-level and\n  - operator-level\n\n  ---> to deliver competitive performance across hardware back-ends.\n\n### Four fundamental challenges at the computation graph level and tensor operator level\n\n1. **High-level dataflow rewriting:**\n    - Different hardware devices may have vastly different memory hierarchies.\n\n    - Enabling strategies to fuse operators and optimize data layouts are crucial for optimizing memory access.\n\n2. **Memory reuse across threads:**\n   - Modern GPUs and specialized accelerators ahve memory that can be shared across compute cores.\n   - Traditional shared-nothing nested parallel model is no longer optimal.\n   - Cooperation among threads on shared memory loaded is required for optimized kernels. \n\n3. **Tensorized compute intrinsics:**\n   - The latest hardware provides new instructions tha\n... (truncated)"
    }
  },
  {
    "name": "andersy005/self-driving-car-nd",
    "stars": 49,
    "description": "Udacity's Self-Driving Car Nanodegree project files and notes.",
    "languages_breakdown": {
      "Jupyter Notebook": 24463527,
      "HTML": 1752848,
      "Python": 366362
    },
    "files": {
      "README.md": "# Udacity - Self-Driving Car NanoDegree\n\n[![Udacity - Self-Driving Car NanoDegree](https://s3.amazonaws.com/udacity-sdc/github/shield-carnd.svg)](http://www.udacity.com/drive)\n\n\n<img src=\"https://github.com/andersy005/self-driving-car-nd/blob/master/computer-vision-notes-and-labs/assets/car.jpeg\" alt=\"Self-Driving Car\" width=\"800px\">\n\n\nUdacity's Self-Driving Car Nanodegree project files and notes.\n\nThis repository is a compilation of project files and lecture notes for [Udacity's Self-Driving Car Engineer Nanodegree program](https://www.udacity.com/drive) which I started working on January 19, 2017.\n\n\n## Program Outline:\n### Term 1: Deep Learning and Computer Vision\n\n\n#### 1. Deep Learning\n- `deep-learning-notes-and-labs`: Notes on Deep Learning, Tensorflow and Keras\n- Project 2: Traffic Sign Classifier (Deep Learning)\n- Project 3: Behavioural Cloning (Deep Learning)\n    - Train a car to drive in a 3D simulator using a deep neural network. \n    - Input data comprises steering angles and camera images captured by driving with a keyboard / mouse / joystick in the simulator.\n\n#### 2. Computer Vision\n- `computer-vision-notes-and-labs`: Notes on Computer Vision\n- Project 1: Finding Lane Lines (Intro to Computer Vision)\n- Project 4: Advanced Lane Lines (Computer Vision)\n- Project 5: Vehicle Detection (Computer Vision)\n\n\n\n### Term 2: Sensor Fusion, Localisation and Control\n\n#### 1. Sensor Fusion\n- Combining lidar and radar data to track objects in the environment using Kalman filters.\n#### 2. Localisation\n- Locate a car relative to the world (Align a car and sensors to the map).\n- Use particle filters to localise the vehicle.\n#### 3. Control\n- Fundamental concepts of robotic control.\n- Build algorithms to steer car and wheels so as to meet an objective.\n\n### Term 3: Path Planning, Controlling a Self-Driving Car\n- Path Planning: Finding a sequence of steps in a maze (navigating cities, parking lots)\n- Put your code in a self-driving car\n"
    }
  },
  {
    "name": "andersy005/keras-yolo",
    "stars": 36,
    "description": "Keras implementation of YOLO (You Only Look Once) : Unified, Real-Time Object Detection",
    "languages_breakdown": {
      "Jupyter Notebook": 70397,
      "Python": 22715
    },
    "files": {
      "README.md": "# Keras YOLO Series\nKeras implementation of YOLO (You Only Look Once) : Unified, Real-Time Object Detection\n\nThis is a [Keras](https://keras.io/)\nimplementation of YOLO, and YOLOv2.\nThis project is mainly based on [darkflow](https://github.com/thtrieu/darkflow)\nand [darknet](https://github.com/pjreddie/darknet).\n\nFor details about YOLO and YOLOv2 please refer to their [project page](https://pjreddie.com/darknet/yolo/) \nand the [paper](https://arxiv.org/abs/1612.08242):\nYOLO9000: Better, Faster, Stronger by Joseph Redmon and Ali Farhadi.\n\n"
    }
  }
]