[
  {
    "name": "YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy",
    "stars": 3304,
    "description": "Diffusion model papers, survey, and taxonomy",
    "languages_breakdown": {},
    "files": {
      "README.md": "# Diffusion Models: A Comprehensive Survey of Methods and Applications\nThis repo is constructed for collecting and categorizing papers about diffusion models according to our survey paperâ€”â€”[_**Diffusion Models: A Comprehensive Survey of Methods and Applications**_](https://arxiv.org/abs/2209.00796), which has been accepted by the journal **ACM Computing Surveys**. Considering the fast development of this field, we will continue to update **both [arxiv paper](https://arxiv.org/abs/2209.00796) and this repo**.\n# Overview\n<div aligncenter><img width=\"900\" alt=\"image\" src=\"https://user-images.githubusercontent.com/62683396/227244860-3608bf02-b2af-4c00-8e87-6221a59a4c42.png\">\n\n# Catalogue\n## [Algorithm Taxonomy](#1)\n### [Sampling-Acceleration Enhancement](#1.1)\n  - [Learning-Free Sampling](#1.1.1)\n    - [SDE Solver](#1.1.1.1)\n    - [ODE Solver](#1.1.1.2)\n  - [Learning-Based Sampling](#1.1.2)\n    - [Optimized Discretization](#1.1.2.1)\n    - [Knowledge Distillation](#1.1.2.2)\n    - [Truncated Diffusion](#1.1.2.3)\n### [Likelihood-Maximization Enhancement](#1.2)\n  - [Noise Schedule Optimization](#1.2.1)\n  - [Reverse Variance Learning](#1.2.2)\n  - [Exact Likelihood Computation](#1.2.3)\n### [Data with Special Structures](#1.3)\n  - [Data with Manifold Structures](#1.3.1)\n    - [Known Manifolds](#1.3.1.1)\n    - [Learned Manifolds](#1.3.1.2)\n  - [Data with Invariant Structures](#1.3.2)\n  - [Discrete Data](#1.3.3)\n### [Diffusion with (Multimodal) LLM](#1.4)\n  - [Simple Combination](#1.4.1)\n  - [Deep Collaboration](#1.4.2)\n### [Diffusion with DPO/RLHF](#1.5)\n\n## [Application Taxonomy](#2)\n* [Computer Vision](#2.1)\n  - [Image Super Resolution, Inpainting and Translation](#2.1.1)\n  - [Semantic Segementation](#2.1.2)\n  - [Video Generation](#2.1.3)\n  - [3D Generation](#2.1.4)\n  - [Anomaly Detection](#2.1.5)\n  - [Object Detection](#2.1.6)\n* [Natural Language Processing](#2.2)\n* [Temporal Data Modeling](#2.3)\n  - [Time-Series Imputation](#2.3.1)\n  - [Time-Seires Forecasting](#2.3.2)\n  - [Waveform Signal Processing](#2.3.3)\n* [Multi-Modal Learning](#2.4)\n  - [Text-to-Image Generation](#2.4.1)\n  - [Text-to-3D Generation](#2.4.2)\n  - [Scene Graph/Layout to Image Generation](#2.4.3)\n  - [Text-to-Audio Generation](#2.4.4)\n  - [Text-to-Motion Generation](#2.4.5)\n  - [Text-to-Video Generation/Editting](#2.4.6)\n* [Robust Learning](#2.5)\n  - [Data Purification](#2.5.1)\n  - [Generating Synthetic Data for Robust Learning](#2.5.2)\n* [Molecular Graph Modeling](#2.6)\n* [Material Design](#2.7)\n* [Medical Image Reconstruction](#2.8)\n\n\n\n## [Connections with Other Generative Models](#3)\n* [Variational Autoencoder](#3.1)\n* [Generative Adversarial Network](#3.2)\n* [Normalizing Flow](#3.3)\n* [Autoregressive Models](#3.4)\n* [Energy-Based Models](#3.5)\n\n<p id=\"1\"></p >\n\n## Algorithm Taxonomy\n<p id=\"1.1\"></p >\n\n### 1. Efficient Sampling\n<p id=\"1.1.1\"></p >\n\n#### 1.1 Learning-Free Sampling\n<p id=\"1.1.1.1\"></p >\n\n##### 1.1.1 SDE Solver\n\n[Score-Based Generative Modeling\nthrough Stochastic Diffe\n... (truncated)"
    }
  },
  {
    "name": "YangLing0818/RPG-DiffusionMaster",
    "stars": 1839,
    "description": "[ICML 2024] Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs (RPG)",
    "languages_breakdown": {
      "Jupyter Notebook": 732274,
      "Python": 154593
    },
    "files": {
      "requirements.txt": "accelerate==0.29.1\r\nasttokens==2.4.1\r\nattrs==23.2.0\r\nbackcall==0.2.0\r\nbeautifulsoup4==4.12.3\r\nbleach==6.1.0\r\ncertifi==2024.2.2\r\ncharset-normalizer==3.3.2\r\ncomm==0.2.2\r\ndecorator==5.1.1\r\ndefusedxml==0.7.1\r\ndiffusers==0.27.2\r\ndocopt==0.6.2\r\neinops==0.7.0\r\nexceptiongroup==1.2.0\r\nexecuting==2.0.1\r\nfastjsonschema==2.19.1\r\nfilelock==3.13.3\r\nfsspec==2024.3.1\r\nhuggingface-hub==0.22.2\r\nidna==3.6\r\nimportlib_metadata==7.1.0\r\nipython==8.12.3\r\nipywidgets==8.1.2\r\njedi==0.19.1\r\nJinja2==3.1.3\r\njsonschema==4.21.1\r\njsonschema-specifications==2023.12.1\r\njupyter_client==8.6.1\r\njupyter_core==5.7.2\r\njupyterlab_pygments==0.3.0\r\njupyterlab_widgets==3.0.10\r\nMarkupSafe==2.1.5\r\nmatplotlib-inline==0.1.6\r\nmistune==3.0.2\r\nmpmath==1.3.0\r\nnbclient==0.10.0\r\nnbconvert==7.16.3\r\nnbformat==5.10.4\r\nnetworkx==3.2.1\r\nnumpy==1.23.0\r\nnvidia-cublas-cu12==12.1.3.1\r\nnvidia-cuda-cupti-cu12==12.1.105\r\nnvidia-cuda-nvrtc-cu12==12.1.105\r\nnvidia-cuda-runtime-cu12==12.1.105\r\nnvidia-cudnn-cu12==8.9.2.26\r\nnvidia-cufft-cu12==11.0.2.54\r\nnvidia-curand-cu12==10.3.2.106\r\nnvidia-cusolver-cu12==11.4.5.107\r\nnvidia-cusparse-cu12==12.1.0.106\r\nnvidia-nccl-cu12==2.19.3\r\nnvidia-nvjitlink-cu12==12.4.127\r\nnvidia-nvtx-cu12==12.1.105\r\nopencv-python==4.9.0.80\r\npackaging==24.0\r\npandocfilters==1.5.1\r\nparso==0.8.4\r\npexpect==4.9.0\r\npickleshare==0.7.5\r\npillow==10.3.0\r\npipreqs==0.5.0\r\nplatformdirs==4.2.0\r\nprompt-toolkit==3.0.43\r\npsutil==5.9.8\r\nptyprocess==0.7.0\r\npure-eval==0.2.2\r\nPygments==2.17.2\r\npython-dateutil==2.9.0.post0\r\nPyYAML==6.0.1\r\npyzmq==25.1.2\r\nreferencing==0.34.0\r\nregex==2023.12.25\r\nrequests==2.31.0\r\nrpds-py==0.18.0\r\nsafetensors==0.4.2\r\nsix==1.16.0\r\nsoupsieve==2.5\r\nstack-data==0.6.3\r\nsympy==1.12\r\ntinycss2==1.2.1\r\ntokenizers==0.15.2\r\ntorch==2.2.2\r\ntorchvision==0.17.2\r\ntornado==6.4\r\ntqdm==4.66.2\r\ntraitlets==5.14.2\r\ntransformers==4.39.3\r\ntriton==2.2.0\r\ntyping_extensions==4.11.0rc1\r\nurllib3==2.2.1\r\nwcwidth==0.2.13\r\nwebencodings==0.5.1\r\nwidgetsnbextension==4.0.10\r\nxformers==0.0.25.post1\r\nyarg==0.1.9\r\nzipp==3.18.1",
      "README.md": "## Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs - ICML 2024\r\n<a href=\"https://trendshift.io/repositories/7230\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/7230\" alt=\"YangLing0818%2FRPG-DiffusionMaster | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\r\n\r\nThis repository contains the official implementation of our [RPG](https://openreview.net/forum?id=DgLFkAPwuZ), accepted by ICML 2024.\r\n\r\n> [**Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs**](https://openreview.net/forum?id=DgLFkAPwuZ)   \r\n> [Ling Yang](https://yangling0818.github.io/), \r\n> [Zhaochen Yu](https://github.com/BitCodingWalkin), \r\n> [Chenlin Meng](https://cs.stanford.edu/~chenlin/),\r\n> [Minkai Xu](https://minkaixu.com/),\r\n> [Stefano Ermon](https://cs.stanford.edu/~ermon/), \r\n> [Bin Cui](https://cuibinpku.github.io/) \r\n> <br>**Peking University, Stanford University, Pika Labs**<br>\r\n\r\n## Introduction\r\n\r\n\r\n<table class=\"center\">\r\n    <tr>\r\n    <td width=100% style=\"border: none\"><img src=\"__asset__/method.png\" style=\"width:100%\"></td>\r\n    </tr>\r\n    <tr>\r\n    <td width=\"100%\" style=\"border: none; text-align: center; word-wrap: break-word\">Overview of our RPG\r\n</td>\r\n  </tr>\r\n</table>\r\n\r\n\r\n**Abstract**: RPG is a powerful training-free paradigm that can utilize proprietary MLLMs (e.g., GPT-4, Gemini-Pro) or open-source local MLLMs (e.g., miniGPT-4) as the **prompt recaptioner and region planner** with our **complementary regional diffusion** to achieve SOTA text-to-image generation and editing. Our framework is very flexible and can generalize to arbitrary MLLM architectures and diffusion backbones. RPG is also capable of generating image with super high resolutions, here is an example:\r\n\r\n<table class=\"center\">\r\n    <tr>\r\n    <td width=100% style=\"border: none\"><img src=\"__asset__/demo/object/icefire.png\" style=\"width:100%\"></td>\r\n    </tr>\r\n    <tr>\r\n    <td width=\"100%\" style=\"border: none; text-align: center; word-wrap: break-word\">Text prompt: A beautiful landscape with a river in the middle the left of the river is in the evening and in the winter with a big iceberg and a small village while some people are skating on the river and some people are skiing, the right of the river is in the summer with a volcano in the morning and a small village while some people are playing.\r\n</td>\r\n  </tr>\r\n</table>\r\n\r\n\r\n\r\n## ðŸš© New Updates \r\n\r\n**[2025.2]** We enhance RPG with LLMs that possess the strongest reasoning capabilities, including [**DeepSeek-R1**](https://github.com/deepseek-ai/DeepSeek-R1), [**OpenAI o3-mini**](https://openai.com/index/openai-o3-mini/), and [**OpenAI o1**](https://openai.com/index/learning-to-reason-with-llms/), and leverage the powerful diffusion backbone [**IterComp**](https://github.com/YangLing0818/IterComp), to achieve outstanding compositional image generation under complex prompts.\r\n\r\n**[2024.10]** We enhance RP\n... (truncated)"
    }
  },
  {
    "name": "YangLing0818/buffer-of-thought-llm",
    "stars": 674,
    "description": "[NeurIPS 2024 Spotlight] Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models",
    "languages_breakdown": {
      "Python": 137421
    },
    "files": {
      "requirements.txt": "accelerate==0.29.3\naiohttp==3.8.4\naiosignal==1.3.1\nannotated-types==0.6.0\nanyio==4.3.0\nargon2-cffi==23.1.0\nargon2-cffi-bindings==21.2.0\narrow==1.3.0\nasttokens==2.4.1\nasync-lru==2.0.4\nasync-timeout==4.0.2\nattrs==23.1.0\nBabel==2.14.0\nbackoff==2.2.1\nbeautifulsoup4==4.12.3\nbitsandbytes==0.43.1\nbleach==6.1.0\ncertifi==2023.5.7\ncffi==1.16.0\ncharset-normalizer==3.1.0\nchess==1.10.0\nclick==8.1.7\ncomm==0.2.2\ncontourpy==1.2.1\ncycler==0.12.1\ndebugpy==1.8.1\ndecorator==5.1.1\ndefusedxml==0.7.1\ndiskcache==5.6.3\ndistro==1.9.0\nexceptiongroup==1.2.1\nexecuting==2.0.1\nfastapi==0.110.2\nfastjsonschema==2.19.1\nfilelock==3.13.4\nfonttools==4.51.0\nfqdn==1.5.1\nfrozenlist==1.3.3\nfsspec==2024.3.1\nh11==0.14.0\nhttpcore==1.0.5\nhttpx==0.27.0\nhuggingface-hub==0.22.2\nidna==3.4\nimportlib_metadata==7.1.0\nimportlib_resources==6.4.0\nipykernel==6.29.4\nipython==8.18.1\nipywidgets==8.1.2\nisoduration==20.11.0\njedi==0.19.1\nJinja2==3.1.3\njson5==0.9.25\njsonpointer==2.4\njsonschema==4.21.1\njsonschema-specifications==2023.12.1\njupyter==1.0.0\njupyter_client==8.6.1\njupyter-console==6.6.3\njupyter_core==5.7.2\njupyter-events==0.10.0\njupyter-lsp==2.2.5\njupyter_server==2.14.0\njupyter_server_terminals==0.5.3\njupyterlab==4.1.6\njupyterlab_pygments==0.3.0\njupyterlab_server==2.26.0\njupyterlab_widgets==3.0.10\nkiwisolver==1.4.5\nMarkupSafe==2.1.5\nmatplotlib==3.8.4\nmatplotlib-inline==0.1.7\nmistune==3.0.2\nmpmath==1.3.0\nmultidict==6.0.4\nnbclient==0.10.0\nnbconvert==7.16.3\nnbformat==5.10.4\nnest-asyncio==1.6.0\nnetworkx==3.2.1\nnotebook==7.1.3\nnotebook_shim==0.2.4\nnumpy==1.24.3\nnvidia-cublas-cu12==12.1.3.1\nnvidia-cuda-cupti-cu12==12.1.105\nnvidia-cuda-nvrtc-cu12==12.1.105\nnvidia-cuda-runtime-cu12==12.1.105\nnvidia-cudnn-cu12==8.9.2.26\nnvidia-cufft-cu12==11.0.2.54\nnvidia-curand-cu12==10.3.2.106\nnvidia-cusolver-cu12==11.4.5.107\nnvidia-cusparse-cu12==12.1.0.106\nnvidia-nccl-cu12==2.19.3\nnvidia-nvjitlink-cu12==12.4.127\nnvidia-nvtx-cu12==12.1.105\nordered-set==4.1.0\noverrides==7.7.0\npackaging==24.0\npandas==2.0.3\npandocfilters==1.5.1\nparso==0.8.4\npexpect==4.9.0\npillow==10.3.0\npip==23.3.1\nplatformdirs==4.2.0\nprometheus_client==0.20.0\nprompt-toolkit==3.0.43\nprotobuf==5.26.1\npsutil==5.9.8\nptyprocess==0.7.0\npure-eval==0.2.2\npycparser==2.22\npydantic==2.7.0\npydantic_core==2.18.1\npydot==2.0.0\npyformlang==1.0.10\nPygments==2.17.2\npyparsing==3.1.2\npython-chess==1.999\npython-dateutil==2.9.0.post0\npython-json-logger==2.0.7\npytz==2024.1\nPyYAML==6.0.1\npyzmq==26.0.2\nqtconsole==5.5.1\nQtPy==2.4.1\nreferencing==0.34.0\nregex==2024.4.16\nrequests==2.31.0\nrfc3339-validator==0.1.4\nrfc3986-validator==0.1.1\nrpds-py==0.18.0\nsafetensors==0.4.3\nscipy==1.13.0\nseaborn==0.13.2\nSend2Trash==1.8.3\nsetuptools==68.2.2\nsix==1.16.0\nsniffio==1.3.1\nsoupsieve==2.5\nstack-data==0.6.3\nstarlette==0.37.2\nsympy==1.12\nterminado==0.18.1\ntiktoken==0.6.0\ntinycss2==1.2.1\ntokenizers==0.19.1\ntomli==2.0.1\ntorch==2.2.2\ntornado==6.4\ntqdm==4.65.0\ntraitlets==5.14.3\ntransformers==4.40.1\ntriton==2.2.0\ntypes-python-dateutil==2.9.0.20240316\ntyping_extensions==4.11.0\ntzdata==2024.1\nuri-templat\n... (truncated)",
      "README.md": "# Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models \r\n\r\n <a href='https://arxiv.org/abs/2406.04271'><img src='https://img.shields.io/badge/arXiv-2406.04271-b31b1b.svg'></a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\r\n\r\nOfficial implementation of our [Buffer of Thoughts (BoT)](https://arxiv.org/abs/2406.04271) framework (**NeurIPS 2024 Spotlight**). Affiliation: Peking University, UC Berkeley, Stanford University\r\n\r\n\r\n## ðŸ“¢ News\r\n[2025.6] ðŸŽ‰ Based on our [Buffer of Thoughts (BoT)](https://arxiv.org/abs/2406.04271), we develop [**ReasonFlux-PRM**](https://arxiv.org/abs/2506.18896), a family of trajectory-aware process reward models (PRMs) for long CoT reasoning in LLMs. ReasonFlux-PRM is able to support **both offline and online reward supervision**, by selecting high-quality training data for model distillation, providing dense process-level rewards for policy optimization during reinforcement learning, and enabling reward-guided test-time scaling. \r\nOur trained PRMs including [ReasonFlux-PRM-7B](https://huggingface.co/Gen-Verse/ReasonFlux-PRM-7B) and [ReasonFlux-PRM-1.5B](https://huggingface.co/Gen-Verse/ReasonFlux-PRM-1.5B) are now available on [HuggingFace-GenX](https://huggingface.co/Gen-Verse). We also release a 7B advanced thinking and reasoning model [ReasonFlux-PRM-Qwen-2.5-7B](https://huggingface.co/Gen-Verse/ReasonFlux-PRM-Qwen-2.5-7B) supervised via our PRM.\r\n\r\n[2025.3] ðŸŽ‰ We release [ReasonFlux-F1-32B](https://huggingface.co/Gen-Verse/ReasonFlux-F1), [ReasonFlux-F1-14B](https://huggingface.co/Gen-Verse/ReasonFlux-F1-14B), [ReasonFlux-F1-7B](https://huggingface.co/Gen-Verse/ReasonFlux-F1-7B), a series of SOTA-level reasoning LLMs by leveraging the **template-augmented reasoning (based on BoT) trajectories** collected from our [ReasonFlux-Zero](https://github.com/Gen-Verse/ReasonFlux). For the training and evaluation scripts, please refer to [Reasonflux-F1](https://github.com/Gen-Verse/ReasonFlux/tree/main/reasonflux-f1) for detail.\r\n\r\n| Task/Pass@1           | [**ReasonFlux-F1-32B**](https://huggingface.co/Gen-Verse/ReasonFlux-F1) | **ReasonFlux-Zero-32B** | **DeepSeek-R1-Distill-32B** | **o1-mini** | **LIMO -32B** | **s1-32B** |\r\n| :------------- | :----------------: | :-------------: | :-------------------: | :-----------------: | :--------: | :--------: |\r\n| MATH500           |      **96.0**      |      91.2      |      94.3      |        90.0        |        90.6         |    93.0    |\r\n| AIME 2024      |      **76.7**      |      56.7      |      72.6      |        56.7        |        50.0         |    56.7    |\r\n| AIME 2025    | **53.3**         | 37.2                     |        46.67        |         50.8         |        37.2         |    49.3    |\r\n| GPQA-Diamond | **67.2**         | 61.2                     |      62.1      |        60.0        |        65.2         |    59.6    |\r\n\r\n[2024.10] ðŸŽ‰ We release [SuperCorrect](https://github.com/YangLing0818/SuperCorrect-llm) based on Buffer of Thoughts, a new self-corr\n... (truncated)"
    }
  }
]