[
  {
    "name": "n00mkrad/cupscale",
    "stars": 2303,
    "description": "Image Upscaling GUI based on ESRGAN",
    "languages_breakdown": {
      "C#": 301341
    },
    "files": {
      "README.md": "# Cupscale\nImage Upscaling GUI based on ESRGAN\n\n![](https://i.imgur.com/ntIuSrv.png)\n\n## Credits:\n\nBased around [xinntao's ESRGAN](https://github.com/xinntao/ESRGAN) implemented via [Joey's Fork](https://github.com/JoeyBallentine/ESRGAN).\n\nAMD/Intel GPU compatibility is possible thanks to BlueAmulet's [esrgan-ncnn-vulkan](https://github.com/BlueAmulet/realsr-ncnn-vulkan) based on nihui's [realsr-ncnn-vulkan](https://github.com/nihui/realsr-ncnn-vulkan) running on Tencent's [ncnn](https://github.com/Tencent/ncnn) framework, as well as [xinntao's Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN).\n\n## Download:\n\n[Get the latest release](https://github.com/n00mkrad/cupscale/releases)\n\n## Installation:\n\nThe application is more or less portable. It's a single executable that you can run anywhere.\n\nTemporary files are stored in the installation directory by default, which is why you shouldn't install the application in protected locations like Program Files.\n\n## Supported AI Backends:\n\n- Nvidia CUDA (Recommended)\n- Vulkan (Works on any modern GPU, but is slower and takes a long time start up)\n- CPU (Works without GPU, but is very slow)\n\n## Features:\n\n- CUDA, Vulkan/NCNN or CPU supported, with included model converter for NCNN\n- On-the-fly Model Interpolation\n- Model Chaining (Run images through multiple models at once)\n- Batch Upscaling (Load a directory or multiple single images)\n- Automatic Image tiling/merging to avoid running out of VRAM\n- Pre-Processing: Optionally downscale images before upscaling\n- Post-Processing: Automatically resize after upscaling\n- Compatible with PNG, JPEG, BMP, WEBP, TGA, DDS images\n- Load image straight out of the clipboard (no need to download images from web)\n- Create various types of comparisons (Side-By-Side, 50/50, and before/after animations as GIF or MP4)\n"
    }
  },
  {
    "name": "n00mkrad/flowframes",
    "stars": 1823,
    "description": "Flowframes Windows GUI for video interpolation using DAIN (NCNN) or RIFE (CUDA/NCNN)",
    "languages_breakdown": {
      "Python": 7257399,
      "C#": 1327379,
      "PowerShell": 8597,
      "Roff": 7997,
      "Batchfile": 2942,
      "Shell": 946
    },
    "files": {
      "README.md": "# Flowframes - Windows GUI for Video Interpolation\n\n## [itch.io (Free Old Builds)](https://nmkd.itch.io/flowframes) | [Patreon (Latest Builds)](https://www.patreon.com/n00mkrad) | [Discord](https://discord.com/invite/eJHD2NSJRe)\n\nFlowframes Windows GUI for video interpolation - Supports RIFE (Pytorch & NCNN), DAIN (NCNN), and FLAVR (Pytorch) implementations.\n\nFlowframes is **open-source donationware**. Builds are released for free on itch after an early-access period on Patreon. This repo's code is complete and does not \"paywall\" experienced users who want to compile the program themselves or want to contribute to the development.\n\nHowever, **I do not provide support for self-built versions** as I can't guarantee that the code of this repo is stable at any given moment.\n\n![img](https://i.imgur.com/HHZxUYo.png)\n\n## Quick Installation\n\n* Download on [itch](https://nmkd.itch.io/flowframes) or, for the most recent beta versions, on [Patreon](https://www.patreon.com/n00mkrad). This repo does not provide builds.\n* Follow the instructions in the installer and wait for it to complete\n* Run Flowframes\n\n\n\n## Using A Pytorch Implementation\n\nFlowframes comes with RIFE-NCNN which runs on Tencent's NCNN framework, which allows it to run on any modern (Vulkan-capable) GPU.\n\nHowever, the official RIFE implementation run best via its original Pytorch implementation.\n\nThe requirements to run these are the following:\n\n* A **modern Nvidia GPU** (750 Ti, 900/1000/1600/2000/3000/4000 Series).\n* A **Python** installation including Pytorch (1.5 or later) as well as the packages `opencv-python`, `sk-video`, `imageio`.\n  * The Flowframes Installer will automatically download all dependencies by default if these requirements are not fullfilled.\n\n[More Details On Python Dependencies](PythonDependencies.md)\n\n\n\n## Configuration\n\nAll Settings have reasonable defaults, so users do not need to do any configuration before using the program.\n\nHere is an explanation of some of the more important settings.\n\n### Application\n\n* Processing Style: Either run all steps at once, or each step manually, in case you want to edit frames, or deduplicate manually.\n* Maximum Video Size: Frames are exported at this resolution if the video is larger. Lower resolutions speed up interpolation a lot.\n* Export Name Pattern: Customize the pattern of the filenames of outputs using variables.\n\n### Interpolation\n\n* Input Media To Preserve: Toggle transfer of Audio, Subtitles and MKV Metadata.\n* Enable Transparency: Interpolate transparency. Only active if the input **and** output support transparency (PNG/GIF).\n* Import HQ JPEGs: Will extract JPEG instead of PNG frames from videos. Fast and lightweight, but with a tiny (invisible) quality loss.\n* Frame De-Duplication: This is meant for 2D animation. Removing duplicates makes a smooth interpolation possible.\n  * You should disable this completely if you only use content without duplicates (e.g. camera footage, CG renders).\n  * \"During Extraction\" works for\n... (truncated)"
    }
  },
  {
    "name": "n00mkrad/text2image-gui",
    "stars": 966,
    "description": "Somewhat modular text2image GUI, initially just for Stable Diffusion",
    "languages_breakdown": {
      "C#": 923404
    },
    "files": {
      "README.md": "# NMKD Stable Diffusion GUI\nSomewhat modular text2image GUI, initially just for Stable Diffusion.\n\nRelies on a slightly customized fork of the InvokeAI Stable Diffusion code: [Code Repo](https://github.com/n00mkrad/stable-diffusion-cust/commits/main)\n\n**Main Guide:**  \n[**System Requirements**](#system-requirements)  \n[**Features and How to Use Them**](#features-and-how-to-use-them)  \n[**Hotkeys (Main Window)**](#hotkeys-main-window)\n\n**Additional Guides:**  \n[**AMD GPU Support**](https://github.com/n00mkrad/text2image-gui/blob/main/docs/Amd.md)  \n[**Inpainting**](https://github.com/n00mkrad/text2image-gui/blob/main/docs/Inpainting.md)  \n\n\n\n## System Requirements\n\n**OS:** Windows 10/11 64-bit\n\n#### Minimum:\n\n- **GPU:** Nvidia GPU with 4 GB VRAM, Maxwell Architecture (2014) or newer\n  - Alternatively, with limited feature support: Any DirectML-capable GPU with 8 GB of VRAM\n\n- **RAM:** 8 GB RAM (Note: Pagefile must be enabled as swapping will occur with only 8 GB!)\n- **Disk:** 10 GB (another free 5 GB for temporary files recommended)\n\n#### Recommended:\n\n- **GPU:** Nvidia GPU with 8 GB VRAM, Pascal Architecture (2016) or newer\n- **RAM:** 16 GB RAM\n- **Disk:** 12 GB on SSD (another free 5 GB for temporary files recommended)\n\n\n\n## Features and How to Use Them\n\n### Prompt Input\n\n- **Multiple prompts at once:** Enter each prompt on a new line (newline-separated). Word wrapping does not count towards this.\n- **Negative Prompt:** Put words or phrases into this box to tell the AI to exclude those things when generating images.\n  - Alternatively, you can also put the negative prompt into the regular prompt box by wrapping it in [brackets].\n\n- **Emphasis:** Use `+` after a word/phrase to make it more impactful, or `-` to do the opposite. You can also use to increase the effect. Wrap your phrase in parentheses if you want to apply it to more than one word.\n  - Each plus/minus applies a multiplier of 1.1. So two `+++` would be 1.1^3 = 1.331, and so on.\n  - You can also type the strength manually after parentheses, e.g. `a (huge)1.33 dog` instead of `a huge+++ dog`\n  - Syntax Examples: `a green++ tree`, `a (big green)+ tree with orange- leaves (in the woods)++`\n\n- **Wildcards:** Fill in words or phrases from a list into the prompt.\n  - Inline: `photo of a ~car,tree,dog~`.\n  - From File: `photo of a ~objects` for loading texts from `objects.txt` in your `Wildcards` folder in the SD GUI root folder.\n  - Order: Use `~` for random/shuffled, `~~` for unchanged order, or `~~~` for sorted (A-Z) mode.\n\n\n\n\n### Additional Inputs\n\n* **Textual Inversion Embeddings:** Select a prompt embedding and add it to your prompt (Path can be set in Settings).\n* **LoRA Files:** (Hidden if no files are in the folder) Select LoRA models and set the weight.\n* **Base Image:** Load an initialization image that will be used together with your text prompt (\"img2img\"), or for inpainting\n  * Loading multiple images means that each image will be processed separately.\n\n\n\n### Stable Diffusion Set\n... (truncated)"
    }
  }
]